%md

# Use Case 2: Ingest Transactional Data from Oracle DB to AWS S3 using GoldenGate
## ğŸ¯ Goal
To continuously replicate transactional data (e.g., from Oracle Core Banking system) to an AWS S3 data lake using Oracle GoldenGate.

ğŸ“ Architecture Overview
pgsql
Copy
Edit
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Oracle Core DB    â”‚ (On-Prem)
 â”‚  â””â”€ Transactions   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
      [Oracle GoldenGate Extract]
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Trail Files (Local)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
      [GoldenGate Distribution Pathway]
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  AWS DMS / GG for  â”‚
 â”‚  Big Data / Custom â”‚
 â”‚     Handler        â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Amazon S3 (Landing)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
### ğŸ”§ Key Components
####  1. Oracle GoldenGate Extract & Replicat
Extracts from Oracle redo/archive logs.

Transforms to trail files.

Replicat pushes to S3 using GoldenGate for Big Data (GGBD) OR via custom handler + S3 sink.

#### 2. GoldenGate for Big Data (GGBD) â†’ S3 Sink
GG Big Data supports native S3 target.

Output formats: JSON, AVRO, Parquet, etc.

### ğŸ’» Sample Configuration Files
ğŸ“ ogg.properties for GoldenGate to S3
properties
Copy
Edit
gg.handlerlist=s3handler
gg.handler.s3handler.type=s3
gg.handler.s3handler.format=json
gg.handler.s3handler.mode=tx
gg.handler.s3handler.s3BucketName=banking-ingest-bucket
gg.handler.s3handler.rootDirectory=corebanking/transactions
gg.handler.s3handler.region=us-east-1
gg.handler.s3handler.fileRollSizeMB=100
gg.handler.s3handler.prefix=txn_
gg.handler.s3handler.fileSuffix=.json
gg.handler.s3handler.encryption=AES256
âœ… This creates files in S3 like:
s3://banking-ingest-bucket/corebanking/transactions/txn_20250527.json

### ğŸ” Authentication Options
Use IAM Role (if running on EC2 or container).

Or set static credentials in aws.properties:

properties
Copy
Edit
aws.accessKeyId=YOUR_ACCESS_KEY
aws.secretAccessKey=YOUR_SECRET_KEY
ğŸ› ï¸ Optional: Use AWS DMS + GoldenGate
GoldenGate writes to Kafka.

AWS DMS reads Kafka and writes to S3 (JSON/Parquet).

### ğŸ§ª Output Sample: JSON Record in S3
json
Copy
Edit
{
  "table": "transactions",
  "operation": "INSERT",
  "timestamp": "2025-05-27T14:32:45Z",
  "data": {
    "txn_id": "TX123456",
    "account_no": "987654321",
    "amount": 150.00,
    "currency": "USD",
    "type": "DEBIT",
    "txn_date": "2025-05-27T14:30:00Z"
  }
}
### âœ… Benefits
Feature	Value
Real-time ingestion	Yes (near real-time using trail files)
Format	JSON/Parquet supported
Querying via Athena	Yes, once partitioned
Secure transfer	Yes (encryption + IAM policies)
